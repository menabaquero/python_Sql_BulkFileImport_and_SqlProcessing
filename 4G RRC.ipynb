{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85396123-b1f2-4ac3-a17d-b52ae1704a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Quarter Report:\n",
    "##lteAudit1_Audit_4G\n",
    "## And In SQLMS create Database\n",
    "#create database lteAudit1_Audit_4G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8351fde1-ff61-4b9d-9f85-d0eff718cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Windows Shell\n",
    "#setx PATH \"%PATH%;C:\\Users\\c00298579\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\"\n",
    "\n",
    "## In Windows Shell\n",
    "# install python pip\n",
    "# https://stackoverflow.com/questions/23708898/pip-is-not-recognized-as-an-internal-or-external-command\n",
    "# En windows terminal, only one time, not each audit\n",
    "##pip install pyodbc\n",
    "\n",
    "# In Python\n",
    "#How to Create a Table in SQL Server using Python\n",
    "#https://datatofish.com/create-table-sql-server-python/\n",
    "\n",
    "#How to Make Inserts Into SQL Server 100x faster with Pyodbc\n",
    "#https://towardsdatascience.com/how-i-made-inserts-into-sql-server-100x-faster-with-pyodbc-5a0b5afdba5\n",
    "\n",
    "#Connecting to MS SQL Server with Windows Authentication using Python?\n",
    "#https://stackoverflow.com/questions/16515420/connecting-to-ms-sql-server-with-windows-authentication-using-python\n",
    "\n",
    "#How to unzip multiple zip files in a folder using python?\n",
    "# https://dev.to/abbazs/how-to-unzip-multiple-zip-files-in-a-folder-using-python-6dd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "# Iterate over all Zip files in the directory\n",
    "###path = 'D:/SQL/2023Q4_11_v3/Rename_lteAudit1 - Copy/'\n",
    "###p = Path('D:/SQL/2023Q4_11_v3/Rename_lteAudit1 - Copy/')\n",
    "###for f in p.glob('*.zip'):\n",
    "###    # Open the Zip file\n",
    "###    with zipfile.ZipFile(f, 'r') as archive:\n",
    "###        # Extract all contents of the Zip file to a directory with the same name as the file\n",
    "###        archive.extractall(path=f'D:/SQL/2023Q4_11_v3/Rename_lteAudit1 - Copy/uncompressed')\n",
    "###        # Print a message indicating that the extraction is complete\n",
    "###        print(f\"Extracted contents from '{f.name}' to '{f.stem}' directory.\")\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ff62e3-d871-4275-b215-e2e3bd8dc629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Loaded: lteAudit1_0\n",
      "File Loaded: lteAudit1_1\n",
      "File Loaded: lteAudit1_2\n",
      "File Loaded: lteAudit1_3\n",
      "File Loaded: lteAudit1_4\n",
      "File Loaded: lteAudit1_5\n",
      "File Loaded: lteAudit1_6\n",
      "File Loaded: lteAudit1_7\n",
      "File Loaded: lteAudit1_8\n",
      "File Loaded: lteAudit1_9\n",
      "File Loaded: lteAudit1_10\n",
      "File Loaded: lteAudit1_11\n",
      "File Loaded: lteAudit1_12\n",
      "File Loaded: lteAudit1_13\n",
      "File Loaded: lteAudit1_14\n",
      "File Loaded: lteAudit1_15\n",
      "File Loaded: lteAudit1_16\n",
      "File Loaded: lteAudit1_17\n",
      "File Loaded: lteAudit1_18\n",
      "File Loaded: lteAudit1_19\n",
      "File Loaded: lteAudit1_20\n",
      "File Loaded: lteAudit1_21\n",
      "File Loaded: lteAudit1_22\n",
      "File Loaded: lteAudit1_23\n",
      "File Loaded: lteAudit1_24\n",
      "File Loaded: lteAudit1_25\n",
      "File Loaded: lteAudit1_26\n",
      "File Loaded: lteAudit1_27\n",
      "File Loaded: lteAudit1_28\n",
      "File Loaded: lteAudit1_29\n",
      "File Loaded: lteAudit1_30\n",
      "File Loaded: lteAudit1_31\n",
      "File Loaded: lteAudit1_32\n",
      "File Loaded: lteAudit1_33\n",
      "File Loaded: lteAudit1_34\n",
      "File Loaded: lteAudit1_35\n",
      "File Loaded: lteAudit1_36\n",
      "File Loaded: lteAudit1_37\n",
      "File Loaded: lteAudit1_38\n",
      "File Loaded: lteAudit1_39\n",
      "File Loaded: lteAudit1_40\n",
      "File Loaded: lteAudit1_41\n",
      "File Loaded: lteAudit1_42\n",
      "File Loaded: lteAudit1_43\n",
      "File Loaded: lteAudit1_44\n",
      "File Loaded: lteAudit1_45\n",
      "File Loaded: lteAudit1_46\n",
      "File Loaded: lteAudit1_47\n",
      "File Loaded: lteAudit1_48\n",
      "File Loaded: lteAudit1_49\n",
      "File Loaded: lteAudit1_50\n",
      "File Loaded: lteAudit1_51\n",
      "File Loaded: lteAudit1_52\n",
      "File Loaded: lteAudit1_53\n",
      "File Loaded: lteAudit1_54\n",
      "File Loaded: lteAudit1_55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c00298579\\AppData\\Local\\Temp\\ipykernel_25392\\1065134027.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sql_query = pd.read_sql_query('''\n"
     ]
    }
   ],
   "source": [
    "# lteAudit1:\n",
    "# Rename files\n",
    "# https://stackoverflow.com/questions/37467561/renaming-multiple-files-in-a-directory-using-python\n",
    "import os\n",
    "path = 'D:/SQL/Audit_4G/Rename_lteAudit1/'\n",
    "files = os.listdir(path)\n",
    "lteAudit=\"lteAudit1_\"\n",
    "lteAudit1FileNumber = 0\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, ''.join([lteAudit, str(index), '.csv'])))\n",
    "    lteAudit1FileNumber = index\n",
    "\n",
    "# lteAudit1-3:\n",
    "import fileinput\n",
    "\n",
    "## In SQLMS\n",
    "##create database lteAudit1_Audit_4G\n",
    "##cursor.execute(\"Use [lteAudit1_Audit_4G]\")\n",
    "\n",
    "# lteAudit1:\n",
    "import pyodbc\n",
    "cnxn = pyodbc.connect(r'Driver=SQL Server;Server=LAPTOP-UNVM0A4T\\SQLEXPRESS;Database=lteAudit1_Audit_4G;Trusted_Connection=yes;')\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "# lteAudit1-3:\n",
    "cursor.execute('''\n",
    "\tCreate Table enodebTable60MinReg\n",
    "\t(\n",
    "\tStartTime DATETIME,\n",
    "\tPeriod INT,\n",
    "\tNeName VARCHAR(45),\n",
    "\teNodeBFunction VARCHAR(45),\n",
    "\tCellID VARCHAR(45),\n",
    "\tCellName VARCHAR(45),\n",
    "\teNodeBID VARCHAR(45),\n",
    "\tCellFDDTDDInd VARCHAR(45),\n",
    "\tTrafficUserMax DECIMAL(20,5),\n",
    "\tTrafficUserAvg DECIMAL(20,5)\n",
    "\t)\n",
    "\t''')\n",
    "cursor.execute('''\n",
    "\tCreate Table enodebTable60MinReg_Total\n",
    "\t(\n",
    "\tStartTime DATETIME,\n",
    "\tPeriod INT,\n",
    "\tNeName VARCHAR(45),\n",
    "\teNodeBFunction VARCHAR(45),\n",
    "\tCellID VARCHAR(45),\n",
    "\tCellName VARCHAR(45),\n",
    "\teNodeBID VARCHAR(45),\n",
    "\tTrafficUserMax DECIMAL(20,5),\n",
    "\tTrafficUserAvg DECIMAL(20,5)\n",
    "\t)\n",
    "\t''')\n",
    "\n",
    "#How to Run the SQL Server BULK INSERT Command from Within a Python Program\n",
    "#https://www.sqlnethub.com/blog/how-to-run-the-sql-server-bulk-insert-command-from-within-a-python-program/\n",
    "# lteAudit1-3:\n",
    "bulkInsertCommand_Part1='''\n",
    "\tBULK \n",
    "\tINSERT dbo.enodebTable60MinReg\n",
    "\tFROM 'D:/SQL/Audit_4G/'''\n",
    "bulkInsertCommand_Part2='''.csv'\n",
    "\tWITH\n",
    "\t(\n",
    "\tFIRSTROW = 2,\n",
    "\tFIELDTERMINATOR = ',',\n",
    "\tROWTERMINATOR = '0x0a'\n",
    "\t)\n",
    "\t'''\t\n",
    "#x is 0 to lteAudit1FileNumber for Audit_4G, if error load one by one and replace \" DST,\" in Start time column by \",\"\n",
    "# lteAudit1 Month1 of Q:\n",
    "for x in range(0, lteAudit1FileNumber+1):\n",
    "  fileNumber = 'lteAudit1_'+str(x)\n",
    "  with fileinput.FileInput('D:/SQL/Audit_4G/'+'Rename_lteAudit1/'+fileNumber+'.csv', inplace=True, backup='.bak') as file:\n",
    "    for line in file:\n",
    "      print(line.replace(' DST,', ' ,'), end='')\n",
    "for x in range(0, lteAudit1FileNumber+1):\n",
    "  fileNumber = 'lteAudit1_'+str(x)\n",
    "  with fileinput.FileInput('D:/SQL/Audit_4G/'+'Rename_lteAudit1/'+fileNumber+'.csv', inplace=True, backup='.bak') as file:\n",
    "    for line in file:\n",
    "      print(line.replace(',NIL', ',0'), end='')\n",
    "\n",
    "# lteAudit1 Month1 of Q:\n",
    "for x in range(0, lteAudit1FileNumber+1):\n",
    "   fileNumber = 'lteAudit1_'+str(x)\n",
    "   print('File Loaded: '+'lteAudit1_'+str(x))\n",
    "   bulkInsertCommand=bulkInsertCommand_Part1+'Rename_lteAudit1/'+fileNumber+bulkInsertCommand_Part2\n",
    "   cursor.execute(bulkInsertCommand)\n",
    "   cnxn.commit()\n",
    "   \n",
    "   \n",
    "#\t/* Step 3: Create enodebTable60MinReg_AddingCells table per eNodeB */\n",
    "# lteAudit1-3:\n",
    "\n",
    "cursor.execute('''\n",
    "\tCreate Table enodebTable60MinReg_AddingCells\n",
    "\t(\n",
    "\tStartTime DATETIME,\n",
    "\tNeName VARCHAR(45),\n",
    "\tTrafficUserMax DECIMAL(20,5),\n",
    "\tTrafficUserAvg DECIMAL(20,5)\n",
    "\t)\n",
    "\t''')\n",
    "\t\n",
    "\t\n",
    "\n",
    "# /* Step 3.1: Insert addition of all cell value on the hour per eNodeB */\n",
    "\n",
    "\t\n",
    "#Insert Table Values From One Database To Another Database\n",
    "#https://www.c-sharpcorner.com/blogs/insert-from-one-table-to-another-both-tables-are-from-diffrent-database-in-sql-server1#:~:text=INSERT%20INTO%20SQL%20statement%20is,tables%20in%20the%20same%20database.\n",
    "\n",
    "# lteAudit1:\n",
    "cursor.execute('''\n",
    "\tINSERT INTO lteAudit1_Audit_4G.dbo.enodebTable60MinReg_AddingCells\n",
    "\tSELECT StartTime, NeName, sum(TrafficUserMax), sum(TrafficUserAvg) FROM lteAudit1_Audit_4G.dbo.enodebTable60MinReg\n",
    "\tGROUP BY StartTime, NeName ORDER BY StartTime ASC\n",
    "\t\t''')\n",
    "\t\t\n",
    "#/* Step 4: Create table All_Network_PerHour to store the Avg and Max user values for all the network */\n",
    "\n",
    "# lteAudit1-3:\n",
    "cursor.execute('''\n",
    "\tCreate Table All_Network_PerHour\n",
    "\t(\n",
    "\tStartTime DATETIME,\n",
    "\tTrafficUserMax DECIMAL(20,5),\n",
    "\tTrafficUserAvg DECIMAL(20,5)\n",
    "\t)\n",
    "\t''')\n",
    "\n",
    "#/* Step 4.1: Insert addition of all cell value on the hour per eNodeB */\n",
    "\t\n",
    "# lteAudit1:\n",
    "cursor.execute('''\n",
    "\tINSERT INTO lteAudit1_Audit_4G.dbo.All_Network_PerHour\n",
    "\tSELECT StartTime, sum(TrafficUserMax), sum(TrafficUserAvg) FROM lteAudit1_Audit_4G.dbo.enodebTable60MinReg\n",
    "\tGROUP BY StartTime ORDER BY StartTime ASC\n",
    "\t\t''')\n",
    "\n",
    "\t\n",
    "# /* Step 5: Create All_Network_PerHour_WitoutTime table */\n",
    "# lteAudit1-3:\n",
    "cursor.execute('''\n",
    "\tCreate Table All_Network_PerHour_WitoutTime\n",
    "\t(\n",
    "\tStartTime DATETIME,\n",
    "\tTrafficUserMax DECIMAL(20,5),\n",
    "\tTrafficUserAvg DECIMAL(20,5)\n",
    "\t)\n",
    "\t''')\n",
    "\n",
    "# lteAudit1-3:\n",
    "# /* Step 4.1: Insert data into table by day */\n",
    "cursor.execute('''\n",
    "\tINSERT INTO All_Network_PerHour_WitoutTime (StartTime, TrafficUserMax, TrafficUserAvg)\n",
    "\t(SELECT DATEADD(dd, 0, DATEDIFF(dd, 0, StartTime)), TrafficUserMax, TrafficUserAvg FROM All_Network_PerHour)\n",
    "\t''')\n",
    "\n",
    "# /* Step 6: All_Network_UserMaxValuesEachDay table: To store peak of User Max for each day */\n",
    "# lteAudit1-3:\n",
    "cursor.execute('''\n",
    "\tCreate Table All_Network_UserMaxValuesEachDay\n",
    "\t(\n",
    "\tStartTime DATETIME,\n",
    "\tTrafficUserMax DECIMAL(20,5),\n",
    "\tTrafficUserAvg DECIMAL(20,5)\n",
    "\t)\n",
    "\t''')\n",
    "\t\n",
    "#/* Step 5.1: Insert peak hour highest UserMax values for each days */\n",
    "# lteAudit1-3:\n",
    "cursor.execute('''\n",
    "\tINSERT INTO All_Network_UserMaxValuesEachDay\n",
    "\tselect cur.StartTime, cur.TrafficUserMax, cur.TrafficUserAvg\n",
    "\tfrom All_Network_PerHour_WitoutTime cur\n",
    "\twhere not exists (\n",
    "\t\tselect * \n",
    "\t\tfrom All_Network_PerHour_WitoutTime high \n",
    "\t\twhere high.StartTime = cur.StartTime\n",
    "\t\tand high.TrafficUserAvg > cur.TrafficUserAvg\n",
    "\t) ORDER BY TrafficUserMax DESC\n",
    "\t''')\n",
    "cnxn.commit()\n",
    "\n",
    "# python pyodbc sql export to csv\n",
    "# https://datatofish.com/export-sql-table-to-csv-python/\n",
    "\n",
    "#In windows command shell: pip install pandas\n",
    "\n",
    "# lteAudit1-3:\n",
    "import pandas as pd\n",
    "\n",
    "# lteAudit1:\n",
    "sql_query = pd.read_sql_query('''\n",
    "                              SELECT * FROM All_Network_UserMaxValuesEachDay ORDER BY TrafficUserAvg DESC\n",
    "                              '''\n",
    "                              ,cnxn) # here, the 'conn' is the variable that contains your database connection information from step 2\n",
    "df = pd.DataFrame(sql_query)\n",
    "df.to_csv (r'D:\\SQL\\Audit_4G\\lteAudit1_Network_UserMaxValuesEachDay.csv', index = False) # place 'r' before the path name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dc3eb6-e113-42b9-a452-20f5ae224afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c00298579\\AppData\\Local\\Temp\\ipykernel_25392\\1401534360.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sql_query2 = pd.read_sql_query('''\n"
     ]
    }
   ],
   "source": [
    "# /* Step 7: Obtain the day and hour of the third maximum value in the All_Network_UserMaxValuesEachDay table (Desired value of the report)*/\n",
    "\n",
    "sql_query2 = pd.read_sql_query('''\n",
    "                              SELECT * FROM All_Network_PerHour WHERE TrafficUserAvg = '2047131.77'\n",
    "                              '''\n",
    "                              ,cnxn) # here, the 'conn' is the variable that contains your database connection information from step 2\n",
    "\n",
    "df2 = pd.DataFrame(sql_query2)\n",
    "df2.to_csv (r'D:\\SQL\\Audit_4G\\DayAndHour_3rdMax_inAll_Network.csv', index = False) # place 'r' before the path name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8389805a-ebb5-4294-a28c-93b8f97f629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c00298579\\AppData\\Local\\Temp\\ipykernel_25392\\770307282.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sql_query3 = pd.read_sql_query('''\n"
     ]
    }
   ],
   "source": [
    "# /* Step 8: Obtain the data for the traffic of all the eNodeBs for the selected day and hour*/\n",
    "\n",
    "\n",
    "sql_query3 = pd.read_sql_query('''\n",
    "                              SELECT * FROM enodebTable60MinReg_AddingCells WHERE StartTime = '1/30/2024 12:00' ORDER BY NeName ASC\n",
    "                              '''\n",
    "                              ,cnxn) # here, the 'conn' is the variable that contains your database connection information from step 2\n",
    "\n",
    "df3 = pd.DataFrame(sql_query3)\n",
    "df3.to_csv (r'D:\\SQL\\Audit_4G\\dataOfTraffic_allEnodeBs_AtPeak.csv', index = False) # place 'r' before the path name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09208-bbf0-4424-b0aa-2352c1f0e458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
